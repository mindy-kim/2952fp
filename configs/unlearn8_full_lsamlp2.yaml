model:
  target: models.transformer.Transformer
  ckpt_path: ./logs/trained_lsamlp/checkpoints/trainstep_checkpoints/model.ckpt
  params:
    num_layers: 5
    mlp_layers:
    - 0
    - 1
    - 2
    - 3
    - 4
    dim_x: 10
    dim_y: 1
    dropout: 0.1
    nhead: 1
    proj_out: false
data:
  target: data.MULData
  params:
    C: 40
    Nf: 8
train:
  experiment:
    name: unlearning
    params:
      lambda1: 0.2
      lambda2: 0.8
      forgetThresh: 0.025
  batch_sz: 256
  lr: 0.0005
  lightning_cfg:
    max_epochs: 50
    limit_train_batches: 100
